<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" dtd-version="1.3" xml:lang="en">
  <body>
    <p>/SequentialEGM</p>
    <p>document</p>
    <sec id="sec:gpr">
      <title>Multivariate Interpolation on Non-Rectilinear Grids</title>
      <p>This section presents alternative interpolation methods for non-rectilinear grids. First, I present the relatively simple case of fast warped interpolation on a curvilinear grid, which improves upon the interpolation in
        <xref ref-type="bibr" rid="White2015">White (2015)</xref>. Then, I present a machine learning approach to interpolation on unstructured grids based on Gaussian Process Regression as presented in
        <xref ref-type="bibr" rid="Scheidegger2019">Scheidegger &amp; Bilionis (2019)</xref>.
      </p>
      <sec id="warped-grid-interpolation-wgi">
        <title>Warped Grid Interpolation (WGI)</title>
        <p>Assume we have a set of points indexed by
          <inline-formula>
            <tex-math><![CDATA[(i,j)]]></tex-math>
          </inline-formula> in two-dimensional space for which we have corresponding functional values in a third dimension, such that
          <inline-formula>
            <tex-math><![CDATA[f(x_{ij},y_{ij}) = z_{ij}]]></tex-math>
          </inline-formula>. In practice, we are interested in cases where the
          <inline-formula>
            <tex-math><![CDATA[z_{ij}]]></tex-math>
          </inline-formula> are difficult to compute and
          <inline-formula>
            <tex-math><![CDATA[f(x_{ij},y_{ij})]]></tex-math>
          </inline-formula> is unknown, so we are unable to compute them at other values of
          <inline-formula>
            <tex-math><![CDATA[x]]></tex-math>
          </inline-formula> and
          <inline-formula>
            <tex-math><![CDATA[y]]></tex-math>
          </inline-formula> — which is why we want to interpolate
          <xref ref-type="fn" rid="qvhe0hmi2o"/>. These
          <inline-formula>
            <tex-math><![CDATA[(x_{ij},y_{ij})]]></tex-math>
          </inline-formula> points however are not evenly spaced and do not form a rectilinear grid which would make it easy to interpolate the function off the grid. Nevertheless, these points do have a regular structure as we will see.
        </p>
        <fig id="fig:warped_interp">
          <label id="fig:warped_interp">Figure 1:</label>
          <alt-text>True function and curvilinear grid of points for which we know the value of the function.</alt-text>
          <graphic xlink:href="Figures/WarpedInterpolation.pdf"/>
          <caption>
            <p>True function and curvilinear grid of points for which we know the value of the function.</p>
          </caption>
        </fig>
        <p>In Figure 
          <xref ref-type="fig" rid="fig:warped_interp">1</xref>, we can see the true function in three-dimensional space, along with the points for which we actually know the value of the function. The underlying regular structure comes from the points’ position in the matrix, the
          <inline-formula>
            <tex-math><![CDATA[(i,j)]]></tex-math>
          </inline-formula> coordinates. If we join the points along every row and every column, we can see that the resulting grid is regular and piecewise affine (curvilinear).
        </p>
        <p>In Figure 
          <xref ref-type="fig" rid="fig:homotopy">2</xref> we see the values of the function at their index coordinate points in the matrix. We can see that there exists a mapping between the curvilinear grid and the index coordinates of the matrix.
        </p>
        <fig id="fig:homotopy">
          <label id="fig:homotopy">Figure 2:</label>
          <alt-text>Homotopy between the curvilinear grid and the index coordinates of the matrix.</alt-text>
          <graphic xlink:href="Figures/Homotopy.pdf"/>
          <caption>
            <p>Homotopy between the curvilinear grid and the index coordinates of the matrix.</p>
          </caption>
        </fig>
        <p>The objective is to be able to interpolate the value of the function at any point off the grid, where presumably we are only interested in points internal to the curvilinear space and not outside the boundaries. For example, we can imagine that we want an approximation to the function at the point
          <inline-formula>
            <tex-math><![CDATA[(x,y) = (3, 5)]]></tex-math>
          </inline-formula> pictured Figure 
          <xref ref-type="fig" rid="fig:mapping">3</xref>. If we could find the corresponding point in the coordinate grid, interpolation would be straightforward. We can find where the
          <inline-formula>
            <tex-math><![CDATA[x]]></tex-math>
          </inline-formula>-coordinate of the point of interest intersects with the index-coordinates of the matrix. This is similar to assuming that we have 3 linear interpolators formed by connecting the points on the green lines in the x-direction, and for each interpolator we can approximate the corresponding y and z values using the grid data. Now, for each circle in Figure 
          <xref ref-type="fig" rid="fig:mapping">3</xref>, we have a corresponding pair
          <inline-formula>
            <tex-math><![CDATA[(y,z)]]></tex-math>
          </inline-formula>, and we can interpolate in the y-direction to find the corresponding z-value for the point’s y-coordinate
          <xref ref-type="fn" rid="ymkzxskw4i"/>.
        </p>
        <fig id="fig:mapping">
          <label id="fig:mapping">Figure 3:</label>
          <alt-text>The method consist of extending the loci of points in the x dimension to find the corresponding crossing points in the y dimension.</alt-text>
          <graphic xlink:href="Figures/Mapping.pdf"/>
          <caption>
            <p>The method consist of extending the loci of points in the
              <inline-formula>
                <tex-math><![CDATA[x]]></tex-math>
              </inline-formula> dimension to find the corresponding crossing points in the
              <inline-formula>
                <tex-math><![CDATA[y]]></tex-math>
              </inline-formula> dimension.
            </p>
          </caption>
        </fig>
      </sec>
    </sec>
    <sec id="unstructured-grids">
      <title>Unstructured Grids</title>
      <p>Unstructured interpolation arises in many dynamic programming applications when using the Endogenous Grid Method because the first-order conditions might be highly non-linear and non-monotonic, or because boundary constraints induce kinks in the policy and value functions. In these cases, the grid points generated by the EGM step are not evenly spaced, leading to the need for curvilinear interpolation. We saw in the previous subsection an approach to curvilinear interpolation based on
        <xref ref-type="bibr" rid="White2015">White (2015)</xref> that is incapable of interpolation on structured grids. A similar approach was presented in
        <xref ref-type="bibr" rid="Ludwig2018">Ludwig &amp; Schön (2018)</xref> which used Delaunay interpolation. However, this approach is not well suited for our purposes because triangulation can be computationally intensive and slow, often offsetting the efficiency gains from the Endogenous Grid Method.
      </p>
      <p>As an alternative to these methods, I introduce the use of Gaussian Process Regression (GPR) along with the Endogenous Grid Method. GPR is computationally efficient, and tools exist to easily parallelize and take advantage of hardware such as Graphics Processing Units (GPU)
        <xref ref-type="fn" rid="vpzbwxocuz"/>.
      </p>
      <sec id="gaussian-process-regression">
        <title>Gaussian Process Regression</title>
        <p>A Gaussian Process is an infinite dimensional random process for which every subset of random variables is jointly Gaussian or has a multivariate normal distribution.</p>
        <disp-formula>
          <label>(2)</label>
          <tex-math><![CDATA[\begin{gathered}
    \mathbf{X} \sim \mathcal{N}(\mathbf{\mu}, \mathbf{\Sigma}) \quad \text{s.t.} \quad x_i \sim \mathcal{N}(\mu_i, \sigma_{ii}) \\
    \text{and} \quad  \sigma_{ij} = \Ex[(x_i - \mu_i)(x_j - \mu_j)] \quad \forall i,j \in \{1, \ldots, n\}.
  \end{gathered}]]></tex-math>
        </disp-formula>
        <p>where</p>
        <disp-formula>
          <label>(3)</label>
          <tex-math><![CDATA[\mathbf{X} = \begin{bmatrix}
    x_1    \\
    x_2    \\
    \vdots \\
    x_n
  \end{bmatrix}
  \quad
  \mathbf{\mu} = \begin{bmatrix}
    \mu_1  \\
    \mu_2  \\
    \vdots \\
    \mu_n
  \end{bmatrix}
  \quad
  \mathbf{\Sigma} = \begin{bmatrix}
    \sigma_{11} & \sigma_{12} & \cdots & \sigma_{1n} \\
    \sigma_{21} & \sigma_{22} & \cdots & \sigma_{2n} \\
    \vdots      & \vdots      & \ddots & \vdots      \\
    \sigma_{n1} & \sigma_{n2} & \cdots & \sigma_{nn}
  \end{bmatrix}.]]></tex-math>
        </disp-formula>
        <p>Being infinitely dimensional, a Gaussian Process can be used to represent a probability distribution over the space of functions in
          <inline-formula>
            <tex-math><![CDATA[n]]></tex-math>
          </inline-formula> dimensions. Thus, a Gaussian Process Regression is used to find the best fit function to a set of data points.
        </p>
        <disp-formula>
          <label>(4)</label>
          <tex-math><![CDATA[\mathbb{P}(\mathbf{f} | \mathbf{X}) = \mathcal{N}(\mathbf{f} | \mathbf{m}, \mathbf{K})]]></tex-math>
        </disp-formula>
        <p>where
          <inline-formula>
            <tex-math><![CDATA[\mathbf{f}]]></tex-math>
          </inline-formula> is the vector of function values at the points
          <inline-formula>
            <tex-math><![CDATA[\mathbf{X}]]></tex-math>
          </inline-formula>,
          <inline-formula>
            <tex-math><![CDATA[\mathbf{m}]]></tex-math>
          </inline-formula> is the mean of the function, and
          <inline-formula>
            <tex-math><![CDATA[\mathbf{K}]]></tex-math>
          </inline-formula> is a kernel function that describes the covariance between the function values at different points.
        </p>
        <p>A standard kernel function is the squared exponential kernel, or the radial basis function kernel, which is defined as</p>
        <disp-formula>
          <label>(5)</label>
          <tex-math><![CDATA[k(\mathbf{x}_i, \mathbf{x}_j) = \sigma^2_f \exp\left(-\frac{1}{2l^2} (\mathbf{x}_i - \mathbf{x}_j)' (\mathbf{x}_i - \mathbf{x}_j)\right).]]></tex-math>
        </disp-formula>
        <p>Using GPR to interpolate a function
          <inline-formula>
            <tex-math><![CDATA[f]]></tex-math>
          </inline-formula>, we can both predict the value of the function at a point
          <inline-formula>
            <tex-math><![CDATA[\mathbf{x}_*]]></tex-math>
          </inline-formula> and the uncertainty in the prediction, which provides useful information as to the accuracy of the approximation.
        </p>
      </sec>
    </sec>
    <sec id="an-example-of-the-gpr">
      <title>An example of the GPR</title>
      <p>In Figure 
        <xref ref-type="fig" rid="fig:true_function">4</xref>, we see the function we are trying to approximate along with a sample of data points for which we know the value of the function. In practice, the value of the function is unknown and/or expensive to compute, so we must use a limited amount of data to approximate it.
      </p>
      <fig id="fig:true_function">
        <label id="fig:true_function">Figure 4:</label>
        <alt-text>The true function that we are trying to approximate and a sample of data points.</alt-text>
        <graphic xlink:href="Figures/true_function.pdf"/>
        <caption>
          <p>The true function that we are trying to approximate and a sample of data points.</p>
        </caption>
      </fig>
      <p>As we discussed, a Gaussian Process is an infinite dimensional random process which can be used to represent a probability of distributions over the space of functions. In Figure 
        <xref ref-type="fig" rid="fig:gpr_sample">5</xref>, we see a random sample of functions from the GPR posterior, which is a Gaussian Process conditioned on fitting the data. From this small sample of functions, we can see that the GP generates functions that fit the data well, and the goal of GPR is to find the one function that best fits the data given some hyperparameters by minimizing the negative log-likelihood of the data.
      </p>
      <fig id="fig:gpr_sample">
        <label id="fig:gpr_sample">Figure 5:</label>
        <alt-text>A random sample of functions from the GPR posterior that fit the data. The goal of GPR is to find the function that best fits the data.</alt-text>
        <graphic xlink:href="Figures/gpr_sample.pdf"/>
        <caption>
          <p>A random sample of functions from the GPR posterior that fit the data. The goal of GPR is to find the function that best fits the data.</p>
        </caption>
      </fig>
      <p>In Figure 
        <xref ref-type="fig" rid="fig:gpr">6</xref>, we see the result of GPR with a particular parametrization
        <xref ref-type="fn" rid="hje9j1apul"/> of the kernel function. The dotted line shows the true function, while the blue dots show the known data points. GPR provides the mean function which best fits the data, represented in the figure as an orange line. The shaded region represents a 95% confidence interval, which is the uncertainty of the predicted function. Along with finding the best fit of the function, GPR provides the uncertainty of the prediction, which is useful information as to the accuracy of the approximation.
      </p>
      <fig id="fig:gpr">
        <label id="fig:gpr">Figure 6:</label>
        <alt-text>GPR finds the function that best fits the data given some hyperparameters. GPR then optimizes over the parameter space to find the function that minimizes the negative log-likelihood of the data.</alt-text>
        <graphic xlink:href="Figures/gpr.pdf"/>
        <caption>
          <p>GPR finds the function that best fits the data given some hyperparameters. GPR then optimizes over the parameter space to find the function that minimizes the negative log-likelihood of the data.</p>
        </caption>
      </fig>
      <p>Web</p>
      <p>[figure]list=no</p>
      <p>[table]list=no</p>
      <p>document</p>
    </sec>
  </body>
  <back>
    <fn-group>
      <fn id="qvhe0hmi2o">
        <label>qvHe0hmI2O</label>
        <p>For this illustration, we generate
          <inline-formula>
            <tex-math><![CDATA[z]]></tex-math>
          </inline-formula>’s arbitrarily using the function
        </p>
        <disp-formula>
          <label>(1)</label>
          <tex-math><![CDATA[f(x,y) = (xy)^{1/4}.]]></tex-math>
        </disp-formula>
      </fn>
      <fn id="ymkzxskw4i">
        <label>ymKzxsKW4I</label>
        <p>For more examples of the Warped Grid Interpolation method in action, see the github project
          <ext-link ext-link-type="uri" xlink:href="https://github.com/alanlujan91/multinterp/blob/main/notebooks/CurvilinearInterpolation.ipynb">
            <monospace>alanlujan91/multinterp</monospace>
          </ext-link>.
        </p>
      </fn>
      <fn id="vpzbwxocuz">
        <label>vPZBWxOcuZ</label>
        <p>
          <xref ref-type="bibr" rid="Gardner2018">Gardner
            <italic>et al.</italic> (2018)
          </xref>
        </p>
      </fn>
      <fn id="hje9j1apul">
        <label>hJE9j1ApUl</label>
        <p>For details see notebook.</p>
      </fn>
    </fn-group>
  </back>
</article>
